{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2b7d697-7809-4728-b81a-14cb15048036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52dca745-c94d-4d9e-95db-60d6bc2cd688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import numpy as np\n",
    "import nltk\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbe842f9-cb05-48e0-bb20-f0c7f14360ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56283ca5-159d-4e32-b100-50362c0e3ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_COLUMNS = ['target', 'ids', 'date', 'flag', 'user', 'text']\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "data = pd.read_csv('sentiment140.csv', encoding=DATASET_ENCODING, names=DATASET_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af416582-f194-4064-89f8-ba9cde058522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target         ids                          date      flag  \\\n",
       "0             0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1             0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2             0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3             0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4             0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...         ...         ...                           ...       ...   \n",
       "1599995       4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996       4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997       4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998       4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999       4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b1fbca1-91fa-4520-9edd-2c8194bf9741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique value counts in the target column:\n",
      "target\n",
      "0    800000\n",
      "4    800000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique value counts in the target column:\")\n",
    "print(data['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f863103-6d29-47bb-a6bd-9e7f6a4da5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    stopwordlist = [\n",
    "        'a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
    "        'and', 'any', 'are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
    "        'being', 'below', 'between', 'both', 'by', 'can', 'd', 'did', 'do',\n",
    "        'does', 'doing', 'down', 'during', 'each', 'few', 'for', 'from',\n",
    "        'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
    "        'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
    "        'into', 'is', 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
    "        'me', 'more', 'most', 'my', 'myself', 'needn', 'no', 'nor', 'now',\n",
    "        'o', 'of', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves',\n",
    "        'out', 'own', 're', 's', 'same', 'she', \"shes\", 'should', \"shouldve\", 'so', 'some', 'such',\n",
    "        't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
    "        'themselves', 'then', 'there', 'these', 'they', 'this', 'those',\n",
    "        'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was',\n",
    "        'we', 'were', 'what', 'when', 'where', 'which', 'while', 'who', 'whom',\n",
    "        'why', 'will', 'with', 'won', 'y', 'you', \"youd\", \"youll\", \"youre\",\n",
    "        \"youve\", 'your', 'yours', 'yourself', 'yourselves'\n",
    "    ]\n",
    "\n",
    "    \n",
    "    def get_wordnet_pos(treebank_tag):\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN\n",
    "    \n",
    "   \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'((www\\.[^\\s]+)|(https?://[^\\s]+))', ' ', text)\n",
    "    text = re.sub(r'@[\\S]+', 'USER', text)\n",
    "    text = re.sub(r'#(\\S+)', r'\\1', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    text = \" \".join([word for word in text.split() if word not in stopwordlist])\n",
    "    tokenizer = RegexpTokenizer(r'\\w+|[^\\w\\s]')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    " \n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token, get_wordnet_pos(tag)) for token, tag in pos_tags]\n",
    "    \n",
    "    return \" \".join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a7afaa3-5f75-43d1-82e9-867a09113a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)      \n",
    "    text = re.sub(r\"@\\w+\", \"USER\", text)     \n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  \n",
    "    text = text.lower()                      \n",
    "    return text\n",
    "\n",
    "data['text'] = data['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c830cb9-edb0-47d8-aaa5-5c0aacf79595",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_samples = data[data['target'] == 4].sample(500, random_state=42)\n",
    "negative_samples = data[data['target'] == 0].sample(500, random_state=42)\n",
    "data_subset = pd.concat([positive_samples, negative_samples])\n",
    "\n",
    "data_subset['target'] = data_subset['target'].replace(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "132c1128-c9ec-4123-a8cd-90278dd1e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    encoded_input = tokenizer(text, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded_input)\n",
    "    scores = output[0][0].cpu().numpy()\n",
    "    scores = softmax(scores)\n",
    "   \n",
    "    negative_score = scores[0]\n",
    "    positive_score = scores[2]\n",
    "    return 1 if positive_score > negative_score else 0\n",
    "\n",
    "\n",
    "data_subset['sentiment'] = data_subset['text'].apply(predict_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf96ad7b-ea4d-4034-a4f5-f2296e73eae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.74      0.76       500\n",
      "    positive       0.75      0.80      0.78       500\n",
      "\n",
      "    accuracy                           0.77      1000\n",
      "   macro avg       0.77      0.77      0.77      1000\n",
      "weighted avg       0.77      0.77      0.77      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = data_subset['target']\n",
    "y_pred = data_subset['sentiment']\n",
    "report = classification_report(y_true, y_pred, target_names=[\"negative\", \"positive\"])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6262ea7-5b16-4597-88b1-35dff3921dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_tweet(tweet):\n",
    "    tweet = clean_text(tweet)\n",
    "    sentiment = predict_sentiment(tweet)\n",
    "\n",
    "   \n",
    "    return \"positive\" if sentiment == 1 else \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "412a2404-f12f-45cf-823b-df59714da4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the tweet 'I hate the website page i did not like it' is negative.\n"
     ]
    }
   ],
   "source": [
    "test_tweet = \"I hate the website page i did not like it\"\n",
    "predicted_sentiment = test_single_tweet(test_tweet)\n",
    "print(f\"The sentiment of the tweet '{test_tweet}' is {predicted_sentiment}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c43bedc-a83e-4672-8fc9-8e9174214b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
